{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Performance')\n",
    "\n",
    "import bert_predict_class\n",
    "import softmax_and_log_dicts\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosinus Ähnlichkeit\n",
    "def get_cosine_sim(A: list[float], B: list[float]) -> float:\n",
    "    return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "# Nimmt einen Satz und gibt einen Array mit Sätzen. Jeder von ihnen hat ein [UNK] Token von links nach rechts.\n",
    "# [MASK] wird nicht zu [UNK] gemapped.\n",
    "def get_sub_sentences(sentence: str) -> list[str]:\n",
    "    sub_sentences = list()\n",
    "    tokens = sentence[:-1].split(' ')\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        s = \"\"\n",
    "        for j in range(len(tokens)):\n",
    "            if i == j:\n",
    "                if tokens[j] == '[MASK]':\n",
    "                    s += '[MASK] '\n",
    "                else:\n",
    "                    s += '[UNK] '\n",
    "            else:\n",
    "                s += tokens[j] + ' '\n",
    "\n",
    "        sub_sentences.append(s[:-1] + '.')\n",
    "\n",
    "    return sub_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit dicts vergleichen\n",
    "def predict_class(bert_predictions, class_dicts=softmax_and_log_dicts.LOG_DICTS):\n",
    "    scores = []\n",
    "    score = 0\n",
    "    for d in class_dicts:\n",
    "        for prediction in bert_predictions:\n",
    "            try:\n",
    "                verb = bert_predict_class.get_verb_lemma(prediction['token_str'])\n",
    "                score += d[0][verb] * prediction['score']\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        scores.append((score))\n",
    "        score = 0\n",
    "    \n",
    "    # softmax und sortiere Score und Labels\n",
    "    softmaxed_scores = bert_predict_class.softmax_basic(np.array(scores))\n",
    "    return softmaxed_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: highlighte die Wörter, die mit XML-Tags markiert waren, im Output-Satz\n",
    "# kann leer gelassen werden!\n",
    "orig_sentence = \"The <e1>bacterial aerosol</e1> was generated from an up-draft <e2>nebulizer</e2>.\"\n",
    "\n",
    "xml_indices = []\n",
    "for index, token in enumerate(orig_sentence.split(' ')):\n",
    "    if re.search('<e[12]>.*</e[12]>', token):\n",
    "        xml_indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gib hier den Satz an, fuer dessen Klassenvorhersage die Token wichtigkeiten berechnet werden sollen.\n",
    "sentence = \"The bacterial aerosol was [MASK] from an up-draft nebulizer.\"\n",
    "# Vorhersage für den originalen Satz\n",
    "bert_pred = bert_predict_class.bert_predict(sentence)\n",
    "class_pred = predict_class(bert_pred)\n",
    "\n",
    "class_predictions = []\n",
    "for sub_sentence in get_sub_sentences(sentence):\n",
    "    bert_sub_pred = bert_predict_class.bert_predict(sub_sentence)\n",
    "    class_sub_pred = predict_class(bert_sub_pred)\n",
    "    class_predictions.append(class_sub_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = []\n",
    "for p in class_predictions:\n",
    "    cosine_similarities.append(get_cosine_sim(p, class_pred))\n",
    "\n",
    "\n",
    "# Berechne min und max\n",
    "X_min = min(cosine_similarities)\n",
    "X_max = max(cosine_similarities)\n",
    "\n",
    "# Cosinusaehnlichkeiten skalieren\n",
    "scaled_similarities = [(x - X_min) / (X_max - X_min) for x in cosine_similarities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-direction: row; font-size: xx-large; '><div style='color: rgb(255, 195.2606923250662, 195.2606923250662)'>The&nbsp</div><div style='color: rgb(255, 204.47748642150208, 204.47748642150208)'>bacterial&nbsp</div><div style='color: rgb(255, 250.30492428836175, 250.30492428836175)'>aerosol&nbsp</div><div style='color: rgb(255, 0.0, 0.0)'>was&nbsp</div><div style='color: rgb(255, 255.0, 255.0)'>[MASK]&nbsp</div><div style='color: rgb(255, 63.531444310202716, 63.531444310202716)'>from&nbsp</div><div style='color: rgb(255, 196.07944995343408, 196.07944995343408)'>an&nbsp</div><div style='color: rgb(255, 231.19590899964416, 231.19590899964416)'>up-draft&nbsp</div><div style='color: rgb(255, 203.74756919989116, 203.74756919989116)'>nebulizer</div>.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTML output erstellen und rendern\n",
    "from IPython.display import HTML\n",
    "\n",
    "STR = \"<div style='display: flex; flex-direction: row; font-size: xx-large; '>\"\n",
    "for index, token in enumerate(sentence[:-1].split(' ')):\n",
    "    STR += f\"<div style='color: rgb(255, {scaled_similarities[index] * 255}, {scaled_similarities[index] * 255})'>{token}&nbsp</div>\"\n",
    "STR = STR[:-11] + \"</div>.</div>\"\n",
    "\n",
    "HTML(STR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
